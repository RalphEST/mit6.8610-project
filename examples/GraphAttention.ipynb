{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30123d0c-520e-418b-9a13-36b9c347058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics + plotting\n",
    "import os, sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 250\n",
    "plt.rcParams[\"font.family\"] = \"sans serif\"\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# custom\n",
    "PROJECT_PATH = '/'.join(os.getcwd().split('/')[:-1])\n",
    "sys.path.insert(1, PROJECT_PATH)\n",
    "\n",
    "from utils import (\n",
    "    data_utils, \n",
    "    eval_utils, \n",
    "    plotting_utils, \n",
    "    train_test_utils\n",
    ")\n",
    "\n",
    "from models import (\n",
    "    gat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70fb7d3b-d159-41b2-aebe-642b5472d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "data_utils = importlib.reload(data_utils)\n",
    "eval_utils = importlib.reload(eval_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd830c9-4a19-4b9c-828e-4568f216917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "if cuda.is_available():\n",
    "    print('using cuda')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "574ca515-9edd-4d18-882f-08dcb408acba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching FHL1 data ... Done\n",
      "Fetching ACTC1 data ... Done\n",
      "Fetching ACTN2 data ... Done\n",
      "Fetching CSRP3 data ... Done\n",
      "Fetching MYBPC3 data ... Done\n",
      "Fetching MYH6 data ... Done\n",
      "Fetching MYH7 data ... Done\n",
      "Fetching MYL2 data ... Done\n",
      "Fetching MYL3 data ... Done\n",
      "Fetching MYOZ2 data ... Done\n",
      "Fetching LDB3 data ... Done\n",
      "Fetching TCAP data ... Done\n",
      "Fetching TNNC1 data ... Done\n",
      "Fetching TNNI3 data ... Done\n",
      "Fetching TNNT2 data ... Done\n",
      "Fetching TPM1 data ... Done\n",
      "Fetching TRIM63 data ... Done\n",
      "Fetching PLN data ... Done\n",
      "Fetching JPH2 data ... Done\n",
      "Fetching FLNC data ... Done\n",
      "Fetching ALPK3 data ... Done\n",
      "Fetching LMNA data ... Done\n",
      "Fetching NEXN data ... Done\n",
      "Fetching VCL data ... Done\n",
      "Fetching MYOM2 data ... Done\n",
      "Fetching CASQ2 data ... Done\n",
      "Fetching CAV3 data ... Done\n",
      "Fetching MYLK2 data ... Done\n",
      "Fetching CRYAB data ... Done\n",
      "Combining tables ... Done\n",
      "Integrating with phenotypes data ...Done\n"
     ]
    }
   ],
   "source": [
    "data = data_utils.load_variation_dataset(\"../data/data/\", \n",
    "                                         \"../gene_list.txt\", \n",
    "                                         [\"embeddings\"], \n",
    "                                         \"../data/phenotypes_hcm_only.parquet\",\n",
    "                                         predict = [\"hcm\"], low_memory=True,\n",
    "                                         embeddings_file='esm2s_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc2a323-949a-4fcb-b609-037d8f7eb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPPIDataframeToNX(df):\n",
    "    Graphtype = nx.Graph()\n",
    "    G = nx.from_pandas_edgelist(df, source='#node1',target='node2',edge_attr=None, create_using=Graphtype)\n",
    "    # print(G.is_directed())\n",
    "    G = from_networkx(G)\n",
    "    return G\n",
    "\n",
    "df = pd.read_csv(\"ppi_networks/ppi2.tsv\",delimiter='\\t')\n",
    "G = convertPPIDataframeToNX(df)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5158347-dbcc-4bd9-b4e4-814a8cc7cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, \n",
    "                train_loader, \n",
    "                optimizer, \n",
    "                loss_fn, \n",
    "                graph, \n",
    "                log_every=10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    all_labels, all_preds = [],[]\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # move batch dictionary to device\n",
    "        data_utils.batch_dict_to_device(batch, device)\n",
    "        labels, features = batch['labels'], batch['embeddings']\n",
    "        \n",
    "        # compute prediction and loss\n",
    "        preds = model(features,graph.edge_index)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # tracking\n",
    "        total_loss += loss.item()\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_preds.append(preds.flatten().detach().cpu())\n",
    "        \n",
    "        # logging\n",
    "        if (i % log_every == 0):\n",
    "            print(f\"\\tBatch {i} | BCE Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    metrics = eval_utils.get_metrics(torch.cat(all_labels), \n",
    "                                     torch.cat(all_preds))\n",
    "    metrics['loss'] = total_loss\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def test(model, \n",
    "         test_loader, \n",
    "         loss_fn,\n",
    "         graph):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels, all_preds = [],[]\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            # move batch dictionary to device\n",
    "            data_utils.batch_dict_to_device(batch, device)\n",
    "            labels, features = batch['labels'], batch['embeddings']\n",
    "\n",
    "            # compute prediction and loss\n",
    "            preds = model(features,graph.edge_index)\n",
    "            loss = loss_fn(preds, labels)\n",
    "\n",
    "            # tracking\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.flatten().detach().cpu())\n",
    "    \n",
    "    metrics = eval_utils.get_metrics(torch.cat(all_labels), \n",
    "                                     torch.cat(all_preds))\n",
    "    metrics['loss'] = total_loss\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train(model, \n",
    "          train_dataset,\n",
    "          test_dataset,\n",
    "          graph,\n",
    "          lr=1e-3, \n",
    "          n_epochs=10,\n",
    "          batch_size=32):\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset = train_dataset, \n",
    "        batch_size = batch_size,\n",
    "        sampler = WeightedRandomSampler(train_dataset.weights('hcm',\n",
    "                                                              flatten_factor=1), \n",
    "                                        num_samples = len(train_dataset)),\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        dataset = test_dataset,\n",
    "        batch_size = batch_size,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    ptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    track_metrics = {'train':{i:None for i in range(n_epochs)}, \n",
    "                     'test': {i:None for i in range(n_epochs)}}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch #{epoch}:\")\n",
    "        train_metrics = train_epoch(model, \n",
    "                                    train_loader, \n",
    "                                    optimizer, \n",
    "                                    loss_fn,\n",
    "                                    graph,\n",
    "                                    log_every=10)\n",
    "        print(\"Train metrics:\")\n",
    "        eval_utils.print_metrics(train_metrics)\n",
    "        test_metrics = test(model, \n",
    "                            test_loader, \n",
    "                            loss_fn,\n",
    "                            graph)\n",
    "        print(\"Test metrics:\")\n",
    "        eval_utils.print_metrics(test_metrics)\n",
    "        \n",
    "        track_metrics['train'][epoch] = train_metrics\n",
    "        track_metrics['test'][epoch] = test_metrics\n",
    "    \n",
    "    return track_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd698e7-6617-445d-85cf-c7dbe73d5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can keep this in json and load it up\n",
    "hparams = {\n",
    "    \"model_params\":{\n",
    "        \"input_size\":320,\n",
    "        \"hid_dim\":100,\n",
    "        \"alpha\": 0.2,\n",
    "        \"num_heads\":5,\n",
    "    },\n",
    "    \"train_params\":{\n",
    "        \"bsz\":16,\n",
    "        \"num_epochs\":100,\n",
    "        \"lr\":1e-3\n",
    "    }\n",
    "}\n",
    "\n",
    "hparams[\"model_params\"][\"ngenes\"] = data.n_genes\n",
    "\n",
    "# \n",
    "# hparams[\"model_params\"][\"input_size\"] = list(train_dataset.dataset.data['embeddings'].values())[0].shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89778fb6-1f2e-4cc6-9502-eafbf2e4d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT_Protein(\n",
       "  (input_layer): Linear(in_features=320, out_features=500, bias=True)\n",
       "  (GATLayer1): GATv2Conv(500, 500, heads=1)\n",
       "  (output_layer1): Linear(in_features=14500, out_features=500, bias=True)\n",
       "  (output_layer): Linear(in_features=500, out_features=1, bias=True)\n",
       "  (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gat.GAT_Protein(**hparams[\"model_params\"])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ae052-ee70-4ad5-80e2-a97ac4d7a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = train(model, \n",
    "                      train_dataset,\n",
    "                      test_dataset, \n",
    "                      lr=hparams[\"train_params\"][\"lr\"], \n",
    "                      n_epochs=hparams[\"train_params\"][\"num_epochs\"],\n",
    "                      batch_size=hparams[\"train_params\"][\"bsz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea87daf-fad7-4fc4-8b10-692fbb72dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics, axes):\n",
    "    metric_types = list(metrics['train'][0].keys())\n",
    "    for mt,ax in zip(metric_types, axes.flatten()):\n",
    "        ax.plot([x[mt] for x in model_metrics['train'].values()])\n",
    "        ax.plot([x[mt] for x in model_metrics['test'].values()])\n",
    "        ax.set_title(mt)\n",
    "    axes[0,0].legend(['train', 'test'])\n",
    "    \n",
    "fig, axes = plt.subplots(2,3,figsize=(12,6), constrained_layout=True)\n",
    "\n",
    "plot_metrics(model_metrics, axes)\n",
    "# fig.savefig('../figures/lr_initial.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
